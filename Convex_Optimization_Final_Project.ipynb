{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jJITGPTLWg_9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import Omniglot\n",
        "import torchvision.models as models\n",
        "from torchvision.models import resnet18\n",
        "from tqdm import tqdm\n",
        "#from transformers import BertModel, BertConfig\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "import os\n",
        "import pandas as pd\n",
        "from torchvision.io import read_image\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import ConcatDataset\n",
        "import torchvision.transforms\n",
        "import torch.utils.data as data\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import transforms\n",
        "from sklearn.metrics import roc_auc_score,average_precision_score, precision_recall_curve\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import Omniglot\n",
        "from torchvision.models import resnet18\n",
        "from tqdm import tqdm\n",
        "import torch.utils.data as data\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, precision_recall_curve\n",
        "import glob\n",
        "from itertools import chain\n",
        "import os\n",
        "import random\n",
        "import zipfile\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "#from linformer import Linformer\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import datasets, transforms\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from matplotlib import pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from torch import optim\n",
        "#from utils import *\n",
        "import logging\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import argparse\n",
        "import configparser"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For on clopud result logging only\n",
        "\n",
        "!pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lK8YBZqPUcUP",
        "outputId": "46715f61-aa7f-4b45-ad9b-b7e5bb83cabc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.16.6-py3-none-any.whl (2.2 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/2.2 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-2.0.1-py2.py3-none-any.whl (266 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.8/266.8 kB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.43 docker-pycreds-0.4.0 gitdb-4.0.11 sentry-sdk-2.0.1 setproctitle-1.3.3 smmap-5.0.1 wandb-0.16.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For on clopud result logging only\n",
        "\n",
        "!wandb login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZkNfHMsUf7l",
        "outputId": "6e70d8ac-6d1d-4d9f-946c-4a224b867fb3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiOixLBhW4-i",
        "outputId": "7ebde677-95be-41ea-999e-a02aa47130da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-03 17:05:57--  https://files.grouplens.org/datasets/movielens/ml-25m.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 261978986 (250M) [application/zip]\n",
            "Saving to: ‘ml-25m.zip’\n",
            "\n",
            "ml-25m.zip          100%[===================>] 249.84M  14.3MB/s    in 19s     \n",
            "\n",
            "2024-05-03 17:06:17 (13.1 MB/s) - ‘ml-25m.zip’ saved [261978986/261978986]\n",
            "\n",
            "Archive:  ml-25m.zip\n",
            "   creating: ml-25m/\n",
            "  inflating: ml-25m/tags.csv         \n",
            "  inflating: ml-25m/links.csv        \n",
            "  inflating: ml-25m/README.txt       \n",
            "  inflating: ml-25m/ratings.csv      \n",
            "  inflating: ml-25m/genome-tags.csv  \n",
            "  inflating: ml-25m/genome-scores.csv  \n",
            "  inflating: ml-25m/movies.csv       \n"
          ]
        }
      ],
      "source": [
        "# Down Load MovieLens25M\n",
        "\n",
        "!wget https://files.grouplens.org/datasets/movielens/ml-25m.zip\n",
        "!unzip ml-25m.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o07Mb2U2-pTp",
        "outputId": "1a888472-3a96-46a6-e168-ee889eb3fd6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-03 17:06:26--  https://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5917549 (5.6M) [application/zip]\n",
            "Saving to: ‘ml-1m.zip’\n",
            "\n",
            "ml-1m.zip           100%[===================>]   5.64M  3.41MB/s    in 1.7s    \n",
            "\n",
            "2024-05-03 17:06:28 (3.41 MB/s) - ‘ml-1m.zip’ saved [5917549/5917549]\n",
            "\n",
            "Archive:  ml-1m.zip\n",
            "   creating: ml-1m/\n",
            "  inflating: ml-1m/movies.dat        \n",
            "  inflating: ml-1m/ratings.dat       \n",
            "  inflating: ml-1m/README            \n",
            "  inflating: ml-1m/users.dat         \n"
          ]
        }
      ],
      "source": [
        "# Down Load MovieLens2M\n",
        "\n",
        "!wget https://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
        "!unzip ml-1m.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_yDvfxhWS2-v"
      },
      "outputs": [],
      "source": [
        "def read_data_ml100k(data_dir, dl_name):\n",
        "\n",
        "    names = ['user_Id', 'item_Id', 'rating', 'timestamp']\n",
        "\n",
        "    if dl_name == \"1m\":\n",
        "      data = pd.read_csv(data_dir,\n",
        "            encoding='latin-1',\n",
        "            header=None,\n",
        "            engine='python',\n",
        "            delimiter='::')\n",
        "\n",
        "      print(data.shape)\n",
        "      data.columns = names\n",
        "      num_users = data.iloc[:,0].unique().shape[0]\n",
        "      num_items = data.iloc[:,1].unique().shape[0]\n",
        "      ratings = data.iloc[:2]\n",
        "      time_step = data.iloc[:3]\n",
        "      return data, num_users, num_items\n",
        "\n",
        "    if dl_name == \"25m\":\n",
        "\n",
        "      data = pd.read_csv(data_dir,\n",
        "                        names=names, engine='python',header=0)\n",
        "      print(data.shape)\n",
        "      num_users = data.user_Id.unique().shape[0]\n",
        "      num_items = data.item_Id.unique().shape[0]\n",
        "      return data, num_users, num_items"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "G7hbSV5FffHA"
      },
      "outputs": [],
      "source": [
        "def build_user_item_matrix(data):\n",
        "\n",
        "    # Pivot table to create user-item matrix\n",
        "\n",
        "    user_item_matrix = data.pivot_table(index=\"user_Id\", columns=\"item_Id\", values=\"rating\", fill_value=0)\n",
        "    return user_item_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H7JVbhIzY5np"
      },
      "outputs": [],
      "source": [
        "data, num_users, num_items = read_data_ml100k(\"/content/ml-25m/ratings.csv\", \"25m\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70rJTHGv-0FE",
        "outputId": "1b8d2bc1-bb04-40b0-98d2-597bcbe9e683"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000209, 4)\n"
          ]
        }
      ],
      "source": [
        "data, num_users, num_items = read_data_ml100k(\"/content/ml-1m/ratings.dat\", \"1m\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98AEACKCg6ke",
        "outputId": "01d4c0fd-2f3c-414a-a050-b6672532b57d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['user_Id', 'item_Id', 'rating', 'timestamp'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9mAd2qonV6i",
        "outputId": "7039c241-6050-40e9-d704-76d52c0a76ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        user_Id  item_Id  rating  timestamp\n",
            "416292     2507     3035       2  974076680\n",
            "683230     4087     2840       4  965431652\n",
            "2434         19      457       3  978146863\n",
            "688533     4118     2804       4  965804599\n",
            "472584     2907      805       4  971838472\n",
            "        user_Id  item_Id  rating  timestamp\n",
            "895536     5412     2683       2  960243649\n",
            "899739     5440      904       5  959995181\n",
            "55687       368     3717       4  976311423\n",
            "63727       425     1721       4  976283587\n",
            "822011     4942     3697       1  962642480\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "print(train_data.head())\n",
        "print(test_data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kssj89YqAPSa",
        "outputId": "f957a03b-3d7f-4c96-d97b-ce24e4219a56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "item_Id  1     2     3     4     5     6     7     8     9     10    ...  \\\n",
            "user_Id                                                              ...   \n",
            "1           5     0     0     0     0     0     0     0     0     0  ...   \n",
            "2           0     0     0     0     0     0     0     0     0     0  ...   \n",
            "3           0     0     0     0     0     0     0     0     0     0  ...   \n",
            "4           0     0     0     0     0     0     0     0     0     0  ...   \n",
            "5           0     0     0     0     0     0     0     0     0     0  ...   \n",
            "\n",
            "item_Id  3943  3944  3945  3946  3947  3948  3949  3950  3951  3952  \n",
            "user_Id                                                              \n",
            "1           0     0     0     0     0     0     0     0     0     0  \n",
            "2           0     0     0     0     0     0     0     0     0     0  \n",
            "3           0     0     0     0     0     0     0     0     0     0  \n",
            "4           0     0     0     0     0     0     0     0     0     0  \n",
            "5           0     0     0     0     0     0     0     0     0     0  \n",
            "\n",
            "[5 rows x 3683 columns]\n",
            "item_Id  1     2     3     4     5     6     7     8     9     10    ...  \\\n",
            "user_Id                                                              ...   \n",
            "1           0     0     0     0     0     0     0     0     0     0  ...   \n",
            "2           0     0     0     0     0     0     0     0     0     0  ...   \n",
            "3           0     0     0     0     0     0     0     0     0     0  ...   \n",
            "4           0     0     0     0     0     0     0     0     0     0  ...   \n",
            "5           0     0     0     0     0     2     0     0     0     0  ...   \n",
            "\n",
            "item_Id  3942  3943  3945  3946  3947  3948  3949  3950  3951  3952  \n",
            "user_Id                                                              \n",
            "1           0     0     0     0     0     0     0     0     0     0  \n",
            "2           0     0     0     0     0     0     0     0     0     0  \n",
            "3           0     0     0     0     0     0     0     0     0     0  \n",
            "4           0     0     0     0     0     0     0     0     0     0  \n",
            "5           0     0     0     0     0     0     0     0     0     0  \n",
            "\n",
            "[5 rows x 3444 columns]\n"
          ]
        }
      ],
      "source": [
        "train_matrix = train_data.pivot_table(index='user_Id', columns='item_Id', values='rating', fill_value=0)\n",
        "test_matrix = test_data.pivot_table(index='user_Id', columns='item_Id', values='rating', fill_value=0)\n",
        "\n",
        "print(train_matrix.head())\n",
        "print(test_matrix.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TydilPn0aN0C",
        "outputId": "cf407c74-3cbe-4597-f293-8653dab9516c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of users: 6040, number of items: 3706\n",
            "matrix sparsity: 0.955316\n"
          ]
        }
      ],
      "source": [
        "sparsity = 1 - len(data) / (num_users * num_items)\n",
        "print(f'number of users: {num_users}, number of items: {num_items}')\n",
        "print(f'matrix sparsity: {sparsity:f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Zz0z3-6ji0IM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class UserItemRatingDataset(Dataset):\n",
        "    def __init__(self, user_item_matrix):\n",
        "\n",
        "        self.ratings = torch.tensor(user_item_matrix.values)\n",
        "        self.users, self.items = self.ratings.nonzero(as_tuple=True)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.users)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        user = self.users[idx]\n",
        "        item = self.items[idx]\n",
        "        rating = self.ratings[user, item]\n",
        "        return user, item, rating\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "JdabvnyVk5LN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# MF model\n",
        "\n",
        "class MatrixFactorization(nn.Module):\n",
        "    def __init__(self, num_users, num_items, num_factors=20):\n",
        "        super(MatrixFactorization, self).__init__()\n",
        "        self.user_factors = nn.Embedding(num_users, num_factors)\n",
        "        self.item_factors = nn.Embedding(num_items, num_factors)\n",
        "\n",
        "\n",
        "        self.user_biases = nn.Embedding(num_users, 1)\n",
        "        self.item_biases = nn.Embedding(num_items, 1)\n",
        "\n",
        "    def forward(self, user, item):\n",
        "\n",
        "\n",
        "        user_embedding = self.user_factors(user)\n",
        "        item_embedding = self.item_factors(item)\n",
        "\n",
        "        # Dot product of user and item embeddings\n",
        "        prediction = (user_embedding * item_embedding).sum(dim=1)\n",
        "\n",
        "        # Add Biases\n",
        "        prediction += self.user_biases(user).squeeze() + self.item_biases(item).squeeze()\n",
        "\n",
        "        return prediction\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "class GradientDescentLineSearch(torch.optim.Optimizer):\n",
        "    def __init__(self, params, lr=0.01, beta=0.5, tolerance=1e-5, max_iter=100):\n",
        "        if lr < 0.0:\n",
        "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
        "        if beta <= 0 or beta >= 1:\n",
        "            raise ValueError(\"Invalid beta value: {}\".format(beta))\n",
        "\n",
        "        defaults = dict(lr=lr, beta=beta, tolerance=tolerance, max_iter=max_iter)\n",
        "        super(GradientDescentLineSearch, self).__init__(params, defaults)\n",
        "\n",
        "    def step(self, closure):\n",
        "\n",
        "        # get initial loss and gradients\n",
        "        loss = closure()\n",
        "        initial_loss = loss.item()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                grad = p.grad.data\n",
        "                current_lr = group['lr']\n",
        "                old_params = p.data.clone()  # Save the current value of the parameters\n",
        "\n",
        "                for _ in range(group['max_iter']):\n",
        "\n",
        "                    # updating the parameter with the current learning rate\n",
        "                    p.data = old_params - current_lr * grad\n",
        "\n",
        "                    optimizer.zero_grad()\n",
        "                    trial_loss = closure().item()  # Compute the new loss\n",
        "\n",
        "                    # Check the loss has reduced or not\n",
        "                    if trial_loss < initial_loss - group['tolerance']:\n",
        "                        initial_loss = trial_loss  # Update initial loss to new lower value\n",
        "                        break  # If Good step found\n",
        "                    else:\n",
        "                        current_lr *= group['beta']  # Reduce learning rate\n",
        "                        p.data = old_params  # Revert to original parameters if no improvement\n",
        "\n",
        "        return loss, current_lr\n",
        "\n"
      ],
      "metadata": {
        "id": "LX8R1TYLvJHY"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "batch_size = 1000\n",
        "\n",
        "feature_dim = 2000\n",
        "\n",
        "train_dataset = UserItemRatingDataset(train_matrix)\n",
        "test_dataset = UserItemRatingDataset(test_matrix)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size = batch_size, shuffle = False)\n",
        "\n",
        "model = MatrixFactorization(num_users=6040, num_items=3952, num_factors=feature_dim).to(device)\n",
        "\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay = 1e-4)\n",
        "\n",
        "optimizer = GradientDescentLineSearch(model.parameters(), lr=0.1, beta=0.8, max_iter=50)\n",
        "\n",
        "def closure(user, item, rating):\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(user, item)\n",
        "    loss = criterion(outputs, rating)\n",
        "    loss.backward()\n",
        "    return loss\n",
        "\n",
        "criterion = nn.MSELoss().to(device)\n",
        "\n",
        "num_epochs = 1000\n",
        "\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    total_loss = 0\n",
        "\n",
        "    for user, item, rating in train_dataloader:\n",
        "\n",
        "        user = user.long().to(device)\n",
        "        item = item.long().to(device)\n",
        "        rating = rating.float().to(device)\n",
        "        loss, current_lr = optimizer.step(lambda: closure(user, item, rating))\n",
        "        total_loss += loss.item()\n",
        "\n",
        "\n",
        "    print(f'Epoch {epoch+1}, Train Loss: {total_loss / len(train_dataloader)}, Current_Lr: {current_lr}')\n",
        "\n",
        "    test_total_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "      model.eval()\n",
        "      for user, item, rating in test_dataloader:\n",
        "\n",
        "        user = user.long().to(device)\n",
        "        item = item.long().to(device)\n",
        "        rating = rating.float().to(device)\n",
        "\n",
        "        prediction = model(user, item)\n",
        "        loss = criterion(prediction, rating)\n",
        "\n",
        "        test_total_loss += loss.item()\n",
        "\n",
        "    print(f'Epoch {epoch+1}, Test Loss: {total_loss / len(test_dataloader)}')\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "id": "74UuKVrWRNPt",
        "outputId": "fe28547d-c189-4533-934f-ee409d1ee5b0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Train Loss: 1854.8788553492705, Current_Lr: 0.1\n",
            "Epoch 1, Test Loss: 7391.830662362018\n",
            "Epoch 2, Train Loss: 291.23731524101953, Current_Lr: 0.1\n",
            "Epoch 2, Test Loss: 1160.602435363466\n",
            "Epoch 3, Train Loss: 72.90368424700142, Current_Lr: 0.1\n",
            "Epoch 3, Test Loss: 290.52662229775194\n",
            "Epoch 4, Train Loss: 23.1913683482919, Current_Lr: 0.1\n",
            "Epoch 4, Test Loss: 92.41933356707369\n",
            "Epoch 5, Train Loss: 8.643149960502406, Current_Lr: 0.1\n",
            "Epoch 5, Test Loss: 34.443597603793165\n",
            "Epoch 6, Train Loss: 3.6022646081879195, Current_Lr: 0.1\n",
            "Epoch 6, Test Loss: 14.355293289345889\n",
            "Epoch 7, Train Loss: 1.6303682834765736, Current_Lr: 0.1\n",
            "Epoch 7, Test Loss: 6.497139278929032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _xla_gc_callback at 0x7a1eaf5b5900>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/jax/_src/lib/__init__.py\", line 98, in _xla_gc_callback\n",
            "    def _xla_gc_callback(*args):\n",
            "KeyboardInterrupt: \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-1fccd60c6f12>\u001b[0m in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrating\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0;31m# PyTorch assumes you have the targets and your inputs are Long tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0muser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Handle `CustomType` automatically\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \"\"\"\n\u001b[0;32m--> 277\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_collate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcollate_fn_map\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0melem_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcollate_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_typed_storage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}